{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Retrieval Methods: Comprehensive Guide to Document Chunking Strategies\n",
    "\n",
    "This notebook provides a comprehensive comparison of document chunking strategies for Retrieval-Augmented Generation (RAG) systems. Document chunking is a critical preprocessing step that directly impacts the quality of information retrieval and subsequent answer generation.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will understand:\n",
    "\n",
    "### Four Core Document Chunking Strategies\n",
    "1. **Baseline Chunking**: Character-based splitting with fixed size limits\n",
    "2. **Recursive Character Chunking**: Hierarchical text splitting that respects natural language boundaries\n",
    "3. **Unstructured Chunking**: Structure-aware document processing that preserves semantic elements\n",
    "4. **Docling Chunking**: Advanced hybrid parsing with sophisticated document understanding\n",
    "\n",
    "### Evaluation Framework\n",
    "- Systematic evaluation methodology for chunking strategies\n",
    "- Key performance metrics for RAG system assessment\n",
    "- Evidence-based recommendations for strategy selection\n",
    "- Practical trade-offs between quality, speed, and complexity\n",
    "\n",
    "## Dataset and Methodology\n",
    "\n",
    "We demonstrate these techniques using research papers from the [mahimaarora025/research_papers](https://huggingface.co/datasets/mahimaarora025/research_papers/tree/main/sample_research_papers) dataset. This dataset contains peer-reviewed academic papers spanning multiple domains:\n",
    "- Analytics and Data Science\n",
    "- Computer Vision\n",
    "- Generative AI\n",
    "- Machine Learning\n",
    "- Statistics\n",
    "\n",
    "The diverse academic content provides an excellent testbed for evaluating chunking strategies across different document structures and content types.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup and Dependencies\n",
    "\n",
    "This section initializes the required libraries and configures the environment for our chunking strategy comparison. We'll use a combination of document processing libraries, language models, and evaluation frameworks.\n",
    "\n",
    "### Key Dependencies\n",
    "- **LangChain**: Document loading and text splitting utilities\n",
    "- **Unstructured**: Advanced document parsing and structure recognition\n",
    "- **Docling**: State-of-the-art document conversion and chunking\n",
    "- **HuggingFace Transformers**: Embedding models for semantic similarity\n",
    "- **Qdrant**: Vector database for storing and retrieving document chunks\n",
    "- **RAGAS**: Evaluation framework for RAG system assessment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aartijha/Desktop/retrieval-playground/rag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports completed\n"
     ]
    }
   ],
   "source": [
    "# Core Python libraries for file handling and data manipulation\n",
    "import os\n",
    "import tempfile\n",
    "import uuid\n",
    "from typing import List, Dict, Any\n",
    "from pathlib import Path\n",
    "\n",
    "# Dataset loading from HuggingFace Hub\n",
    "from datasets import load_dataset\n",
    "\n",
    "# LangChain ecosystem for document processing and language model integration\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# Advanced document processing libraries\n",
    "from unstructured.partition.pdf import partition_pdf  # PDF parsing with structure recognition\n",
    "from unstructured.chunking.title import chunk_by_title  # Title-based intelligent chunking\n",
    "from docling.document_converter import DocumentConverter  # Advanced document conversion\n",
    "from docling.chunking import HybridChunker  # Hybrid semantic-syntactic chunking\n",
    "\n",
    "# Vector database and embeddings for semantic search\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "# Data analysis and evaluation frameworks\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from retrieval_playground.src.pre_retrieval.chunking_evaluation import ChunkingEvaluator\n",
    "\n",
    "# Additional Docling components for markdown processing\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_docling.loader import ExportType\n",
    "from langchain_docling import DoclingLoader\n",
    "\n",
    "# Environment variable management\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# System configuration and API keys\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")  # Gemini API for language model operations\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")  # Qdrant cloud instance URL\n",
    "QDRANT_KEY = os.getenv(\"QDRANT_KEY\")  # Qdrant authentication key\n",
    "EMBEDDING_MODEL = \"Qwen/Qwen3-Embedding-0.6B\"  # Lightweight multilingual embedding model\n",
    "\n",
    "print(\"Imports completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 22:41:16,008 - INFO - Use pytorch device_name: mps\n",
      "2025-09-20 22:41:16,008 - INFO - Load pretrained SentenceTransformer: Qwen/Qwen3-Embedding-0.6B\n",
      "2025-09-20 22:41:20,307 - INFO - 1 prompt is loaded, with the key: query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized\n"
     ]
    }
   ],
   "source": [
    "# Verify API credentials are available\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise ValueError(\"Please set GOOGLE_API_KEY environment variable\")\n",
    "\n",
    "# Initialize Google Gemini language model for text generation and evaluation\n",
    "# Using Gemini 2.0 Flash for fast inference with low temperature for consistency\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.1,  # Low temperature for deterministic outputs\n",
    "    google_api_key=GOOGLE_API_KEY\n",
    ")\n",
    "\n",
    "# Initialize HuggingFace embedding model for semantic similarity computation\n",
    "# Qwen3-Embedding-0.6B provides efficient multilingual embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL\n",
    ")\n",
    "\n",
    "print(\"Models initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Loading and Preprocessing\n",
    "\n",
    "This section demonstrates loading a research paper to serve as our test document for comparing chunking strategies. We'll use a representative academic paper that contains typical document structures found in research literature.\n",
    "\n",
    "### Data Source\n",
    "The test document comes from the research papers collection available at:\n",
    "https://huggingface.co/datasets/mahimaarora025/research_papers/tree/main/sample_research_papers\n",
    "\n",
    "### Document Characteristics\n",
    "Academic papers provide excellent test cases for chunking strategies because they contain:\n",
    "- Abstract and introduction sections\n",
    "- Multiple hierarchical headings\n",
    "- Mathematical formulations and equations\n",
    "- References and citations\n",
    "- Tables and figures with captions\n",
    "- Mixed text densities and complexity levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"Generative_AI_2025_Frozen_in_Time__Parameter-Efficient_Time_Series_Transformers_via___Reservoir-Ind.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Initialize PDF loader for the selected research paper\n",
    "loader = PyPDFLoader(str(pdf_path))\n",
    "pdf_docs = loader.load()  # Load all pages as separate document objects\n",
    "\n",
    "# Extract text content from all pages\n",
    "sample_data = []\n",
    "for i in range(len(pdf_docs)):\n",
    "    sample_data.append(pdf_docs[i].page_content)\n",
    "\n",
    "# Combine all pages into a single text document with page breaks preserved\n",
    "# Using double newlines to maintain natural document flow for chunking\n",
    "sample_data = '\\n\\n'.join(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Chunking Strategy Implementations\n",
    "\n",
    "This section provides hands-on demonstrations of four distinct chunking approaches. Each strategy represents a different philosophy for dividing documents into manageable pieces while preserving semantic coherence and structural integrity.\n",
    "\n",
    "## Strategy 1: Baseline Character-Based Chunking\n",
    "\n",
    "### Overview\n",
    "The baseline approach uses simple character counting to divide text into fixed-size chunks. This method prioritizes speed and simplicity over semantic preservation.\n",
    "\n",
    "### Characteristics\n",
    "- **Speed**: Fastest execution time\n",
    "- **Simplicity**: Minimal configuration required\n",
    "- **Limitations**: May split sentences, paragraphs, or concepts mid-way\n",
    "- **Best Use Cases**: Large-scale processing where speed trumps precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 22:41:40,414 - WARNING - Created a chunk of size 5502, which is longer than the specified 5000\n",
      "2025-09-20 22:41:40,415 - WARNING - Created a chunk of size 6621, which is longer than the specified 5000\n",
      "2025-09-20 22:41:40,415 - WARNING - Created a chunk of size 5268, which is longer than the specified 5000\n",
      "2025-09-20 22:41:40,416 - WARNING - Created a chunk of size 6493, which is longer than the specified 5000\n",
      "2025-09-20 22:41:40,416 - WARNING - Created a chunk of size 5953, which is longer than the specified 5000\n",
      "2025-09-20 22:41:40,417 - WARNING - Created a chunk of size 5565, which is longer than the specified 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE CHUNKING RESULTS\n",
      "Number of chunks: 8\n",
      "--------------------------------------------------\n",
      "Frozen in Time: Parameter-Efficient Time Series\n",
      "Transformers via Reservoir-Induced Feature Expansion\n",
      "and Fixed Random Dynamics\n",
      "Pradeep Singha,*, Mehak Sharmaa, Anupriya Deya and Balasubramanian Ramana\n",
      "aMachine Intelligence Lab, Department of Computer Science and Engineering, IIT Roorkee, Roorkee-247667, India\n",
      "ORCID (Pradeep Singh): https://orcid.org/0000-0002-5372-3355, ORCID (Mehak Sharma):\n",
      "https://orcid.org/0009-0001-3102-1045, ORCID (Anupriya Dey): https://orcid.org/0009-0000-1630-1017, ORCID\n",
      "(Balasubramanian Raman): https://orcid.org/0000-0001-6277-6267\n",
      "Abstract. Transformers are the de-facto choice for sequence mod-\n",
      "elling, yet their quadratic self-attention and weak temporal bias can\n",
      "make long-range forecasting both expensive and brittle. We intro-\n",
      "duce FreezeTST, a lightweight hybrid that interleavesfrozen random-\n",
      "feature (reservoir) blocks with standard trainable Transformer lay-\n",
      "ers. The frozen blocks endow the network with rich nonlinear mem-\n",
      "ory at no optimisation cost; the trainable layers learn to query this\n",
      "memory through self-attention. The design cuts trainable parame-\n",
      "ters and also lowers wall-clock training time, while leaving infer-\n",
      "ence complexity unchanged. On seven standard long-term forecast-\n",
      "ing benchmarks, FreezeTST consistently matches or surpasses spe-\n",
      "cialised variants such as Informer, Autoformer, and PatchTST; with\n",
      "substantially lower compute. Our results show that embedding reser-\n",
      "voir principles within Transformers offers a simple, principled route\n",
      "to efficient long-term time-series prediction.\n",
      "1 Introduction\n",
      "Forecasting the future evolution of high-dimensional time series\n",
      "underpins safety-critical tasks such as renewable-grid dispatch, in-\n",
      "traday portfolio re-balancing, urban congestion mitigation, clini-\n",
      "cal decision-support and early warning of epidemiological surges\n",
      "[17, 7, 21, 36, 34]. What makes these problems hard is the simultane-\n",
      "ous presence of (i) long-range dependencies that may span hundreds\n",
      "of steps, (ii) strong seasonality and abrupt regime shifts, and (iii)\n",
      "training sets that are small relative to the combinatorial space of tem-\n",
      "poral patterns. Transformer encoders have emerged as a promising\n",
      "remedy because self-attention provides a content-adaptive alternative\n",
      "to the fixed convolution or recurrent receptive fields of earlier models\n",
      "[30]. Yet two structural flaws limit their effectiveness when horizons\n",
      "stretch into the hundreds: the O(T2) memory and time complex-\n",
      "ity of full attention, and the fact that positional encodings merely\n",
      "tag rather than enforce chronology, so permutation-invariant heads\n",
      "can still blur causal order. Empirically, even carefully engineered\n",
      "variants—Informer with ProbSparse attention [37], Autoformer with\n",
      "auto-correlation blocks [33], FEDformer with Fourier filters [38],\n",
      "Pyraformer with pyramidal multi-resolution attention [19], and Log-\n",
      "Trans with log-sparse attention [18]—fail to dominate across the\n",
      "∗ Corresponding Author. Email: pradeep.cs@sric.iitr.ac.in\n",
      "Long-Sequence Time-Series Forecasting (LSTF) benchmark; a re-\n",
      "cent work by Zeng et al. shows several cases where a one-layer lin-\n",
      "ear extrapolator wins outright [35]. These observations signal that\n",
      "further architectural principles, not just attention accelerators, are re-\n",
      "quired.\n",
      "Reservoir computing offers a complementary principle. By fixing\n",
      "the weights of a large nonlinear dynamical system and training only\n",
      "a linear read-out, echo-state networks (ESNs) turn temporal credit\n",
      "assignment into a convex, single-step regression problem while re-\n",
      "taining universal approximation power in the limit of infinite width\n",
      "[15, 16, 20]. The cost is a design trade-off: a spectral radius close\n",
      "to unity grants long memory but risks numerical instability, whereas\n",
      "heavy damping stabilises the dynamics at the price of premature for-\n",
      "getting. Recent work has begun to fuse these ideas with attention.\n",
      "Shen et al. froze alternate layers of a BERT encoder and observed\n",
      "comparable accuracy on language benchmarks at half the training\n",
      "cost [28]. Their results suggest that random, untrained transforma-\n",
      "tions can act as useful priors rather than noise—raising an open ques-\n",
      "tion for forecasting:\n",
      "Can a Transformer for time-series forecasting inherit the\n",
      "memory capacity of an echo-state reservoir, and if so, how\n",
      "should one combine the sequential bias of a reservoir with the\n",
      "pattern-matching flexibility of self-attention so that each com-\n",
      "pensates for the other’s weaknesses?\n",
      "We answer in the affirmative with a hybrid Reservoir-Transformer\n",
      "that interposes a frozen, randomly initialised block between atten-\n",
      "tion layers. The reservoir continually integrates incoming patches,\n",
      "providing a stable state vector that preserves sub-sequence statistics\n",
      "far beyond the Transformer’s sliding window, while attention learns\n",
      "to query this state adaptively. Because the recurrent/frozen weights\n",
      "are never updated, the model’s trainable parameter count and mem-\n",
      "ory footprint are roughly halved, yet its receptive field extends well\n",
      "past the H = 96 −720-step horizons used in the LSTF suite. Ex-\n",
      "tensive experiments on ETTh/ETTm, Weather, Electricity and ILI\n",
      "data [23, 37] show that our model matches or exceeds the strongest\n",
      "published baselines, including PatchTST and the best linear meth-\n",
      "ods, with up to 22% shorter training time. A supporting theoretical\n",
      "analysis (§3.2) proves that (i) the alternating frozen/trainable stack\n",
      "is non-expansive, ensuring gradient stability, and (ii) the reservoir’s\n",
      "arXiv:2508.18130v1  [cs.LG]  25 Aug 2025\n"
     ]
    }
   ],
   "source": [
    "# Configure baseline character-based text splitter\n",
    "# This approach splits text based on character count with minimal intelligence\n",
    "baseline_splitter = CharacterTextSplitter(\n",
    "    chunk_size=5000,        # Target chunk size in characters\n",
    "    chunk_overlap=100,      # Character overlap between consecutive chunks\n",
    "    separator=\"\\n\\n\"        # Preferred split point (paragraph breaks)\n",
    ")\n",
    "\n",
    "# Apply baseline chunking to the sample document\n",
    "baseline_chunks = baseline_splitter.split_text(sample_data)\n",
    "\n",
    "# Display results summary\n",
    "print(\"BASELINE CHUNKING RESULTS\")\n",
    "print(f\"Number of chunks: {len(baseline_chunks)}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Show first chunk as example\n",
    "print(baseline_chunks[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 2: Recursive Character Chunking\n",
    "\n",
    "### Overview\n",
    "Recursive character chunking employs a hierarchical approach that attempts to split text at natural boundaries while respecting size constraints. This method balances efficiency with semantic preservation.\n",
    "\n",
    "### Splitting Hierarchy\n",
    "The algorithm tries to split text in the following order of preference:\n",
    "1. **Paragraph breaks** (`\\n\\n`) - Preserves conceptual boundaries\n",
    "2. **Line breaks** (`\\n`) - Maintains sentence structure when possible\n",
    "3. **Spaces** (` `) - Avoids breaking words\n",
    "4. **Character-level** - Last resort when size constraints are strict\n",
    "\n",
    "### Characteristics\n",
    "- **Intelligence**: Respects natural text boundaries\n",
    "- **Flexibility**: Configurable separator hierarchy\n",
    "- **Balance**: Good trade-off between speed and quality\n",
    "- **Best Use Cases**: General-purpose text chunking for most applications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECURSIVE CHUNKING RESULTS\n",
      "Number of chunks: 15\n",
      "--------------------------------------------------\n",
      "Frozen in Time: Parameter-Efficient Time Series\n",
      "Transformers via Reservoir-Induced Feature Expansion\n",
      "and Fixed Random Dynamics\n",
      "Pradeep Singha,*, Mehak Sharmaa, Anupriya Deya and Balasubramanian Ramana\n",
      "aMachine Intelligence Lab, Department of Computer Science and Engineering, IIT Roorkee, Roorkee-247667, India\n",
      "ORCID (Pradeep Singh): https://orcid.org/0000-0002-5372-3355, ORCID (Mehak Sharma):\n",
      "https://orcid.org/0009-0001-3102-1045, ORCID (Anupriya Dey): https://orcid.org/0009-0000-1630-1017, ORCID\n",
      "(Balasubramanian Raman): https://orcid.org/0000-0001-6277-6267\n",
      "Abstract. Transformers are the de-facto choice for sequence mod-\n",
      "elling, yet their quadratic self-attention and weak temporal bias can\n",
      "make long-range forecasting both expensive and brittle. We intro-\n",
      "duce FreezeTST, a lightweight hybrid that interleavesfrozen random-\n",
      "feature (reservoir) blocks with standard trainable Transformer lay-\n",
      "ers. The frozen blocks endow the network with rich nonlinear mem-\n",
      "ory at no optimisation cost; the trainable layers learn to query this\n",
      "memory through self-attention. The design cuts trainable parame-\n",
      "ters and also lowers wall-clock training time, while leaving infer-\n",
      "ence complexity unchanged. On seven standard long-term forecast-\n",
      "ing benchmarks, FreezeTST consistently matches or surpasses spe-\n",
      "cialised variants such as Informer, Autoformer, and PatchTST; with\n",
      "substantially lower compute. Our results show that embedding reser-\n",
      "voir principles within Transformers offers a simple, principled route\n",
      "to efficient long-term time-series prediction.\n",
      "1 Introduction\n",
      "Forecasting the future evolution of high-dimensional time series\n",
      "underpins safety-critical tasks such as renewable-grid dispatch, in-\n",
      "traday portfolio re-balancing, urban congestion mitigation, clini-\n",
      "cal decision-support and early warning of epidemiological surges\n",
      "[17, 7, 21, 36, 34]. What makes these problems hard is the simultane-\n",
      "ous presence of (i) long-range dependencies that may span hundreds\n",
      "of steps, (ii) strong seasonality and abrupt regime shifts, and (iii)\n",
      "training sets that are small relative to the combinatorial space of tem-\n",
      "poral patterns. Transformer encoders have emerged as a promising\n",
      "remedy because self-attention provides a content-adaptive alternative\n",
      "to the fixed convolution or recurrent receptive fields of earlier models\n",
      "[30]. Yet two structural flaws limit their effectiveness when horizons\n",
      "stretch into the hundreds: the O(T2) memory and time complex-\n",
      "ity of full attention, and the fact that positional encodings merely\n",
      "tag rather than enforce chronology, so permutation-invariant heads\n",
      "can still blur causal order. Empirically, even carefully engineered\n",
      "variants—Informer with ProbSparse attention [37], Autoformer with\n",
      "auto-correlation blocks [33], FEDformer with Fourier filters [38],\n",
      "Pyraformer with pyramidal multi-resolution attention [19], and Log-\n",
      "Trans with log-sparse attention [18]—fail to dominate across the\n",
      "∗ Corresponding Author. Email: pradeep.cs@sric.iitr.ac.in\n",
      "Long-Sequence Time-Series Forecasting (LSTF) benchmark; a re-\n",
      "cent work by Zeng et al. shows several cases where a one-layer lin-\n",
      "ear extrapolator wins outright [35]. These observations signal that\n",
      "further architectural principles, not just attention accelerators, are re-\n",
      "quired.\n",
      "Reservoir computing offers a complementary principle. By fixing\n",
      "the weights of a large nonlinear dynamical system and training only\n",
      "a linear read-out, echo-state networks (ESNs) turn temporal credit\n",
      "assignment into a convex, single-step regression problem while re-\n",
      "taining universal approximation power in the limit of infinite width\n",
      "[15, 16, 20]. The cost is a design trade-off: a spectral radius close\n",
      "to unity grants long memory but risks numerical instability, whereas\n",
      "heavy damping stabilises the dynamics at the price of premature for-\n",
      "getting. Recent work has begun to fuse these ideas with attention.\n",
      "Shen et al. froze alternate layers of a BERT encoder and observed\n",
      "comparable accuracy on language benchmarks at half the training\n",
      "cost [28]. Their results suggest that random, untrained transforma-\n",
      "tions can act as useful priors rather than noise—raising an open ques-\n",
      "tion for forecasting:\n",
      "Can a Transformer for time-series forecasting inherit the\n",
      "memory capacity of an echo-state reservoir, and if so, how\n",
      "should one combine the sequential bias of a reservoir with the\n",
      "pattern-matching flexibility of self-attention so that each com-\n",
      "pensates for the other’s weaknesses?\n",
      "We answer in the affirmative with a hybrid Reservoir-Transformer\n",
      "that interposes a frozen, randomly initialised block between atten-\n",
      "tion layers. The reservoir continually integrates incoming patches,\n",
      "providing a stable state vector that preserves sub-sequence statistics\n",
      "far beyond the Transformer’s sliding window, while attention learns\n",
      "to query this state adaptively. Because the recurrent/frozen weights\n",
      "are never updated, the model’s trainable parameter count and mem-\n",
      "ory footprint are roughly halved, yet its receptive field extends well\n"
     ]
    }
   ],
   "source": [
    "# Configure recursive character text splitter with hierarchical boundary detection\n",
    "# This approach intelligently chooses split points based on natural text structure\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=5000,                    # Target chunk size in characters\n",
    "    chunk_overlap=50,                   # Overlap for context continuity\n",
    "    separators=[\"\\n\\n\", \"\\n\"]           # Hierarchical split preferences: paragraphs, then lines\n",
    ")\n",
    "\n",
    "# Apply recursive chunking strategy to the sample document\n",
    "recursive_chunks = recursive_splitter.split_text(sample_data)\n",
    "\n",
    "# Display results summary\n",
    "print(\"RECURSIVE CHUNKING RESULTS\")\n",
    "print(f\"Number of chunks: {len(recursive_chunks)}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Show first chunk demonstrating boundary-aware splitting\n",
    "print(recursive_chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 3: Unstructured Document-Aware Chunking\n",
    "\n",
    "### Overview\n",
    "The Unstructured library provides sophisticated document parsing that recognizes and preserves document structure. This approach understands document elements like titles, headers, paragraphs, lists, and tables before applying chunking logic.\n",
    "\n",
    "### Document Understanding Capabilities\n",
    "- **Element Detection**: Automatically identifies titles, headers, body text, captions\n",
    "- **Structure Preservation**: Maintains hierarchical relationships between elements\n",
    "- **Content Classification**: Distinguishes between different types of content\n",
    "- **Intelligent Grouping**: Chunks content based on semantic coherence rather than arbitrary size\n",
    "\n",
    "### Characteristics\n",
    "- **Accuracy**: High-quality structure recognition\n",
    "- **Semantic Preservation**: Maintains document logic and flow\n",
    "- **Flexibility**: Handles diverse document formats and layouts\n",
    "- **Best Use Cases**: Documents with clear structure, academic papers, reports, books\n",
    "\n",
    "### Implementation Details\n",
    "We'll process the PDF directly to extract structural elements before applying title-based chunking:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 22:41:42,652 - INFO - pikepdf C++ to Python logger bridge initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n",
      "UNSTRUCTURED CHUNKING RESULTS\n",
      "Number of chunks: 6\n",
      "--------------------------------------------------\n",
      "5 2 0 2\n",
      "\n",
      "g u A 5 2\n",
      "\n",
      "]\n",
      "\n",
      "G L . s c [\n",
      "\n",
      "1 v 0 3 1 8 1 . 8 0 5 2 : v i X r a\n",
      "\n",
      "Frozen in Time: Parameter-Efficient Time Series Transformers via Reservoir-Induced Feature Expansion and Fixed Random Dynamics Pradeep Singha,*, Mehak Sharmaa, Anupriya Deya and Balasubramanian Ramana\n",
      "\n",
      "aMachine Intelligence Lab, Department of Computer Science and Engineering, IIT Roorkee, Roorkee-247667, India ORCID (Pradeep Singh): https://orcid.org/0000-0002-5372-3355, ORCID (Mehak Sharma): https://orcid.org/0009-0001-3102-1045, ORCID (Anupriya Dey): https://orcid.org/0009-0000-1630-1017, ORCID (Balasubramanian Raman): https://orcid.org/0000-0001-6277-6267\n",
      "\n",
      "Abstract. Transformers are the de-facto choice for sequence mod- elling, yet their quadratic self-attention and weak temporal bias can make long-range forecasting both expensive and brittle. We intro- duce FreezeTST, a lightweight hybrid that interleaves frozen random- feature (reservoir) blocks with standard trainable Transformer lay- ers. The frozen blocks endow the network with rich nonlinear mem- ory at no optimisation cost; the trainable layers learn to query this memory through self-attention. The design cuts trainable parame- ters and also lowers wall-clock training time, while leaving infer- ence complexity unchanged. On seven standard long-term forecast- ing benchmarks, FreezeTST consistently matches or surpasses spe- cialised variants such as Informer, Autoformer, and PatchTST; with substantially lower compute. Our results show that embedding reser- voir principles within Transformers offers a simple, principled route to efficient long-term time-series prediction.\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Parse PDF with structure recognition using Unstructured library\n",
    "# Fast strategy balances speed with reasonable accuracy for document element detection\n",
    "elements = partition_pdf(\n",
    "    pdf_path, \n",
    "    strategy=\"fast\",                    \n",
    "    infer_table_structure=True          # Attempt to preserve table structure\n",
    ")\n",
    "\n",
    "# Apply title-based intelligent chunking that respects document hierarchy\n",
    "# This groups content under relevant headings and maintains semantic coherence\n",
    "unstructured_chunks = chunk_by_title(\n",
    "    elements, \n",
    "    max_characters=5000                 # Maximum chunk size while preserving structure\n",
    ")\n",
    "\n",
    "# Convert chunk objects to text strings for analysis (limiting for demo purposes)\n",
    "unstructured_chunks = [str(chunk) for chunk in unstructured_chunks[:6]]\n",
    "\n",
    "# Display results summary\n",
    "print(\"UNSTRUCTURED CHUNKING RESULTS\")\n",
    "print(f\"Number of chunks: {len(unstructured_chunks)}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Show first chunk demonstrating structure-aware processing\n",
    "print(unstructured_chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 4: Docling Advanced Hybrid Chunking\n",
    "\n",
    "### Overview\n",
    "Docling represents the current state-of-the-art in document processing, offering advanced PDF parsing with conversion to structured markdown format. The hybrid chunker combines semantic understanding with syntactic rules for optimal chunk boundaries.\n",
    "\n",
    "### Advanced Processing Pipeline\n",
    "1. **Document Conversion**: PDF to structured markdown with layout preservation\n",
    "2. **Element Recognition**: Advanced AI-powered detection of document components\n",
    "3. **Hybrid Chunking**: Combines token-level and semantic-level chunking strategies\n",
    "4. **Header-Aware Splitting**: Respects markdown headers for natural boundaries\n",
    "\n",
    "### Key Innovations\n",
    "- **AI-Powered Parsing**: Uses machine learning models for superior accuracy\n",
    "- **Layout Understanding**: Preserves spatial relationships and document flow\n",
    "- **Multi-Modal Processing**: Handles text, images, tables, and complex layouts\n",
    "- **Semantic Chunking**: Considers content meaning in addition to structure\n",
    "\n",
    "### Characteristics\n",
    "- **Accuracy**: Highest quality document understanding\n",
    "- **Completeness**: Preserves maximum document information\n",
    "- **Computational Cost**: Most resource-intensive approach\n",
    "- **Best Use Cases**: High-value documents, complex layouts, maximum quality requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 22:41:46,971 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-20 22:41:47,015 - INFO - Going to convert document batch...\n",
      "2025-09-20 22:41:47,015 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e647edf348883bed75367b22fbe60347\n",
      "2025-09-20 22:41:47,030 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-09-20 22:41:47,031 - WARNING - The plugin langchain_docling will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
      "2025-09-20 22:41:47,031 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-09-20 22:41:47,037 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-09-20 22:41:47,039 - WARNING - The plugin langchain_docling will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
      "2025-09-20 22:41:47,039 - INFO - Registered ocr engines: ['easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-09-20 22:41:47,086 - INFO - Accelerator device: 'mps'\n",
      "2025-09-20 22:41:48,889 - INFO - Accelerator device: 'mps'\n",
      "2025-09-20 22:41:49,715 - INFO - Accelerator device: 'mps'\n",
      "2025-09-20 22:41:50,137 - INFO - Processing document Generative_AI_2025_Frozen_in_Time__Parameter-Efficient_Time_Series_Transformers_via___Reservoir-Ind.pdf\n",
      "2025-09-20 22:42:06,554 - INFO - Finished converting document Generative_AI_2025_Frozen_in_Time__Parameter-Efficient_Time_Series_Transformers_via___Reservoir-Ind.pdf in 19.58 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCLING CHUNKING RESULTS\n",
      "Number of chunks: 9\n",
      "--------------------------------------------------\n",
      "## Frozen in Time: Parameter-Efficient Time Series Transformers via Reservoir-Induced Feature Expansion and Fixed Random Dynamics  \n",
      "Pradeep Singh a, * , Mehak Sharma a , Anupriya Dey a and Balasubramanian Raman a a Machine Intelligence Lab, Department of Computer Science and Engineering, IIT Roorkee, Roorkee-247667, India ORCID (Pradeep Singh): https://orcid.org/0000-0002-5372-3355, ORCID (Mehak Sharma):  \n",
      "https://orcid.org/0009-0001-3102-1045, ORCID (Anupriya Dey): https://orcid.org/0009-0000-1630-1017, ORCID (Balasubramanian Raman): https://orcid.org/0000-0001-6277-6267  \n",
      "Abstract. Transformers are the de-facto choice for sequence modelling, yet their quadratic self-attention and weak temporal bias can make long-range forecasting both expensive and brittle. We introduce FreezeTST , a lightweight hybrid that interleaves frozen randomfeature (reservoir) blocks with standard trainable Transformer layers. The frozen blocks endow the network with rich nonlinear memory at no optimisation cost; the trainable layers learn to query this memory through self-attention. The design cuts trainable parameters and also lowers wall-clock training time, while leaving inference complexity unchanged. On seven standard long-term forecasting benchmarks, FreezeTST consistently matches or surpasses specialised variants such as Informer, Autoformer, and PatchTST; with substantially lower compute. Our results show that embedding reservoir principles within Transformers offers a simple, principled route to efficient long-term time-series prediction.\n"
     ]
    }
   ],
   "source": [
    "# Configure markdown header-based splitter for structured document processing\n",
    "# This respects the hierarchical structure created by Docling's markdown conversion\n",
    "splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=[\n",
    "        (\"#\", \"Header_1\"),              # Top-level headers (titles, major sections)\n",
    "        (\"##\", \"Header_2\"),             # Second-level headers (subsections)\n",
    "    ],\n",
    "    strip_headers=False                 # Preserve headers in chunks for context\n",
    ")\n",
    "\n",
    "# Initialize Docling loader with advanced hybrid chunking capabilities\n",
    "# Combines PDF parsing, markdown conversion, and intelligent chunking\n",
    "loader = DoclingLoader(\n",
    "    file_path=pdf_path,\n",
    "    export_type=ExportType.MARKDOWN,   # Convert to structured markdown format\n",
    "    chunker=HybridChunker(              # Advanced semantic-syntactic chunking\n",
    "        tokenizer=EMBEDDING_MODEL,      # Use same tokenizer as embedding model\n",
    "        max_tokens=100                  # Conservative token limit for fine-grained chunks\n",
    "    )\n",
    ")\n",
    "\n",
    "# Process document through Docling pipeline\n",
    "docs = loader.load()\n",
    "\n",
    "# Apply header-aware splitting to the markdown-converted content\n",
    "# Creates chunks that respect document structure and semantic boundaries\n",
    "docling_chunks = [\n",
    "    split.page_content \n",
    "    for doc in docs \n",
    "    for split in splitter.split_text(doc.page_content)\n",
    "]\n",
    "\n",
    "# Display results summary\n",
    "print(\"DOCLING CHUNKING RESULTS\")\n",
    "print(f\"Number of chunks: {len(docling_chunks)}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Show first chunk demonstrating advanced structure preservation\n",
    "print(docling_chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking Strategy Comparative Analysis\n",
    "\n",
    "This section provides a quantitative comparison of the four chunking strategies implemented above. We'll examine key metrics including chunk count, average chunk length, and qualitative characteristics to understand the trade-offs between different approaches.\n",
    "\n",
    "## Comparative Metrics\n",
    "\n",
    "The analysis focuses on several key dimensions:\n",
    "- **Chunk Count**: Total number of chunks generated\n",
    "- **Average Length**: Mean character count per chunk\n",
    "- **Consistency**: Variance in chunk sizes\n",
    "- **Boundary Quality**: How well chunks respect semantic boundaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNKING STRATEGY COMPARISON\n",
      "======================================================================\n",
      "    Strategy  Chunks Avg Length               Description\n",
      "    Baseline       8       6020 Character-based splitting\n",
      "   Recursive      15       3216  Boundary-aware splitting\n",
      "Unstructured       6       3716   Structure-aware parsing\n",
      "     Docling       9       6551   Advanced hybrid parsing\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define strategy comparison dataset with descriptive metadata\n",
    "strategies = [\n",
    "    (\"Baseline\", baseline_chunks, \"Character-based splitting\"),\n",
    "    (\"Recursive\", recursive_chunks, \"Boundary-aware splitting\"), \n",
    "    (\"Unstructured\", unstructured_chunks, \"Structure-aware parsing\"),\n",
    "    (\"Docling\", docling_chunks, \"Advanced hybrid parsing\")\n",
    "]\n",
    "\n",
    "# Calculate comparative metrics for each chunking strategy\n",
    "comparison_data = []\n",
    "for name, chunks, description in strategies:\n",
    "    # Compute average chunk length as primary size metric\n",
    "    avg_length = sum(len(chunk) for chunk in chunks) / len(chunks)\n",
    "    \n",
    "    # Compile strategy performance summary\n",
    "    comparison_data.append({\n",
    "        \"Strategy\": name,\n",
    "        \"Chunks\": len(chunks),              # Total number of chunks produced\n",
    "        \"Avg Length\": f\"{avg_length:.0f}\",  # Mean characters per chunk\n",
    "        \"Description\": description          # Strategy characterization\n",
    "    })\n",
    "\n",
    "# Create comparison DataFrame for structured analysis\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Display formatted comparison results\n",
    "print(\"CHUNKING STRATEGY COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Database Integration and Collection Management\n",
    "\n",
    "This section demonstrates connecting to Qdrant, a high-performance vector database, to explore existing chunk collections. Vector databases are essential for RAG systems as they enable semantic search and similarity-based retrieval of document chunks.\n",
    "\n",
    "## Qdrant Vector Database\n",
    "Qdrant provides:\n",
    "- **High Performance**: Optimized for similarity search at scale\n",
    "- **Flexibility**: Support for various distance metrics and filtering\n",
    "- **Scalability**: Handles large collections efficiently\n",
    "- **Integration**: Seamless integration with embedding models\n",
    "\n",
    "## Collection Exploration\n",
    "We'll examine existing collections to understand how different chunking strategies have been previously processed and stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 22:42:53,445 - INFO - HTTP Request: GET https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qdrant connection established\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 22:42:53,776 - INFO - HTTP Request: GET https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333/collections \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AVAILABLE QDRANT COLLECTIONS\n",
      "----------------------------------------\n",
      "Collection: docling\n",
      "\n",
      "Collection: unstructured\n",
      "\n",
      "Collection: baseline\n",
      "\n",
      "Collection: recursive_character\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Establish connection to Qdrant vector database\n",
    "# Check for required credentials before attempting connection\n",
    "if not QDRANT_URL or not QDRANT_KEY:\n",
    "    print(\"Warning: Qdrant credentials not found. Please set QDRANT_URL and QDRANT_KEY\")\n",
    "    qdrant_client = None\n",
    "else:\n",
    "    # Initialize Qdrant client with cloud credentials\n",
    "    qdrant_client = QdrantClient(\n",
    "        url=QDRANT_URL,    # Cloud instance endpoint\n",
    "        api_key=QDRANT_KEY # Authentication key\n",
    "    )\n",
    "    print(\"Qdrant connection established\")\n",
    "    \n",
    "    # Retrieve and display available vector collections\n",
    "    # Each collection typically represents a different chunking strategy or dataset\n",
    "    collections = qdrant_client.get_collections()\n",
    "    print(\"\\nAVAILABLE QDRANT COLLECTIONS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if collections.collections:\n",
    "        # List all collections with their basic information\n",
    "        for collection in collections.collections:\n",
    "            print(f\"Collection: {collection.name}\")\n",
    "            # Additional collection metadata could be displayed here\n",
    "            print()\n",
    "    else:\n",
    "        print(\"No collections found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:09:55,873 - INFO - HTTP Request: POST https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333/collections/baseline/points/scroll \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='0025580a-754e-4fed-9c65-c5c8eff536ea' payload={'page_content': 'edge classification), ensuring broad coverage for\\nevaluating graph reasoning.\\nGraph-to-text augmentation. Unlike prior work\\nthat tokenizes structural features using GNN en-\\ncoders, we revisit the pure graph-to-text paradigm.\\nTaking node-level tasks as an example, for a target\\nnode vi, we extract itsh-hop subgraph and describe\\nall node features Ti = {x(vj) | j ∈ N(i) ∪ {i}},\\nand edge relations Ei = {x(ejk) | vj, vk ∈\\nN(i) ∪ {i}} within the subgraph using natural lan-\\nguage, where N(i) is the neighborhood of vi. To\\nmaintain input tractability for large graphs with\\nverbose node texts (e.g., citation networks with ti-\\ntles and abstracts), we apply DEEP SEEK -V3 for\\nautomatic summarization. Prompt templates are\\nprovided in Appendix B.\\nReasoning-trace extraction. A distinctive fea-\\nture of our dataset construction is the inclusion of\\nexplicit reasoning traces for each answer. Specif-\\nically, each subgraph query Qi consists of node\\nfeatures Ti, edge relations Ei, and a prompt tem-\\nplate PG,τ tailored to the graph structure G and\\ntask type τ, serving as input to the LLM. We then\\ninput Qi into DEEP SEEK -R1 to generate an ex-\\nplicit reasoning trace Ri and a final prediction Yi,\\nas illustrated in Figure 1. Formally, this process\\ncan be represented as:\\nQi → (Yi, Ri).\\nQuality control. We apply a three-stage filtering\\nprocess:\\n1. Information sufficiency : remove isolated\\nnodes and trivial subgraphs.\\n2. Answer validity: discard samples where the\\npredicted answer Yi mismatches the gold label\\nor contains sensitive content.\\n3. Rationale coherence: retain only rationales\\nthat exhibit reasonable length and logical con-\\nsistency.\\nThe final corpus contains 10,000 graph reasoning\\nexamples across multiple domains and tasks, each\\npaired with an explicit chain-of-thought explana-\\ntion.\\n2.3 Graph-R1\\nBuilding on the graph–reasoning corpus described\\nabove, we develop GRAPH -R1 , an LLM-based\\nframework for solving graph machine learning\\ntasks through explicit reasoning. Training pro-\\nceeds in two stages: (1) joint instruction tuning\\nKnowledge GraphMolecular DiagramCitation Network\\nNode DescriptionEdges(Nodepairs)\\nSubgraph to TextGraph-R1\\nPrompt Construction\\nReasoning+ Answer\\nTaskDescription\\nGraph Structured DataSubgraphextraction\\n…\\nFigure 2: GRAPH -R1 framework. Graphs are linearized\\ninto a graph description language, and a task-aware\\nprompt guides the LLM to produce explicit reasoning\\nand the final answer.\\nacross multiple tasks and domains, and (2) rein-\\nforcement learning to refine reasoning quality. To\\nsupport smaller LLM backbones, we introduce a\\nrethink template that encourages deeper semantic\\nand structural analysis, leading to more robust and\\ninterpretable multi-step deductions. This pipeline\\nenables GRAPH -R1 to advance zero-shot graph\\nreasoning with large language models.\\n2.3.1 Reasoning Knowledge Learning via\\nFull-Parameter Fine-Tuning\\nIn Phase 1, we perform joint instruction tuning\\nacross node-, edge-, and graph-level tasks from', 'metadata': {'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Yicong Wu; Guangyue Lu; Yuan Zuo; Huarong Zhang; Junjie Wu', 'doi': 'https://doi.org/10.48550/arXiv.2508.17387', 'license': 'http://creativecommons.org/licenses/by-nc-sa/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': 'Graph-R1: Incentivizing the Zero-Shot Graph Learning Capability in LLMs via Explicit Reasoning', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2508.17387v1', 'source': 'Analytics_2025_Graph-R1__Incentivizing_the_Zero-Shot_Graph_Learning_Capability_in_LLMs___via_Ex.pdf', 'total_pages': 19, 'page': 2, 'page_label': '3', 'chunking_strategy': 'baseline', 'chunk_id': 'b6e4c427-0db1-46d9-b94e-313385c9e1f3'}} vector=None shard_key=None order_value=None\n",
      "id='01bb5461-70bc-4c0b-a809-68ae4901b93d' payload={'page_content': '2025; Xia et al., 2024; Chen et al., 2024d). Yet,\\nthese methods still rely on rigid GNN heads and\\nrequire retraining for each task. Another approach\\ndelegates prediction to the LLM while incorporat-\\ning structural signals from a frozen GNN via cross-\\nmodal projection (Tang et al., 2024; He et al., 2025;\\nWang et al., 2024a). Unfortunately, the separation\\nof training between components results in weak\\ntask conditioning and limited transferability. More\\ntightly coupled methods—such as GOFA (Kong\\net al., 2024)—inject GNN features directly into the\\nLLM token stream at inference time. While this\\nimproves zero-shot accuracy, it introduces substan-\\ntial computational overhead and still struggles with\\ngeneralization across tasks and domains.\\nFrom graph structureto text-based reason-then-\\npredict. Recent advances in Large Reasoning\\nModels (LRMs) (e.g., DEEP SEEK -R1 (DeepSeek-\\nAI et al., 2025)) renew our interest in the graph-\\nto-text paradigm, driven by their ability to gener-\\nate explicit reasoning processes. These models\\ncan potentially compensate for the lack of hand-\\ncrafted structural priors and offer an interpretable,\\nzero-shot-capable alternative for graph learning.\\nCrucially, many canonical graph tasks—such as\\n1\\narXiv:2508.17387v1  [cs.LG]  24 Aug 2025', 'metadata': {'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Yicong Wu; Guangyue Lu; Yuan Zuo; Huarong Zhang; Junjie Wu', 'doi': 'https://doi.org/10.48550/arXiv.2508.17387', 'license': 'http://creativecommons.org/licenses/by-nc-sa/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': 'Graph-R1: Incentivizing the Zero-Shot Graph Learning Capability in LLMs via Explicit Reasoning', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2508.17387v1', 'source': 'Analytics_2025_Graph-R1__Incentivizing_the_Zero-Shot_Graph_Learning_Capability_in_LLMs___via_Ex.pdf', 'total_pages': 19, 'page': 0, 'page_label': '1', 'chunking_strategy': 'baseline', 'chunk_id': 'cb661c44-aac6-443f-a77f-2f565aebef33'}} vector=None shard_key=None order_value=None\n"
     ]
    }
   ],
   "source": [
    "scroll_iter = qdrant_client.scroll(\n",
    "    collection_name=\"baseline\",\n",
    "    limit=2          \n",
    ")\n",
    "\n",
    "points, next_page = scroll_iter\n",
    "for p in points:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Evaluation Framework\n",
    "\n",
    "This section implements a rigorous evaluation methodology to assess the real-world performance of different chunking strategies. We'll use a complete RAG pipeline with standardized test queries to measure retrieval quality and answer generation effectiveness.\n",
    "\n",
    "## Evaluation Methodology\n",
    "\n",
    "### Test Framework\n",
    "- **RAGAS Metrics**: Industry-standard RAG evaluation framework\n",
    "- **Standardized Queries**: Consistent test questions across all strategies\n",
    "- **Controlled Variables**: Same embedding model, LLM, and retrieval parameters\n",
    "- **Multiple Dimensions**: Retrieval quality, answer relevance, faithfulness, precision, recall\n",
    "\n",
    "### Key Performance Indicators\n",
    "1. **Answer Relevancy**: How well generated answers address the question\n",
    "2. **Faithfulness**: Accuracy and consistency with source material\n",
    "3. **Context Precision**: Quality of retrieved chunks for answering\n",
    "4. **Context Recall**: Completeness of information retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Sample query:\n",
      "Question: How does MC3G improve upon existing counterfactual explanation methods, particularly concerning cost computation and causal dependencies?\n",
      "Source: Analytics_2025_MC3G__Model_Agnostic_Causally_Constrained_Counterfactual_Generation.pdf\n"
     ]
    }
   ],
   "source": [
    "# Load standardized test queries for consistent evaluation across all chunking strategies\n",
    "# These queries are designed to test different aspects of retrieval and comprehension\n",
    "import json\n",
    "with open(\"../retrieval_playground/tests/test_queries.json\", 'r') as f:\n",
    "    test_queries = json.load(f)\n",
    "\n",
    "# Display sample query to demonstrate evaluation approach\n",
    "print(\"\\nSample Test Query:\")\n",
    "print(f\"Question: {test_queries[0]['user_input']}\")\n",
    "print(f\"Source Document: {test_queries[0]['source_file']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:21.086 INFO model_manager - _initialize_models: 🔄 ModelManager: Initializing shared AI models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:21,086 - INFO - 🔄 ModelManager: Initializing shared AI models...\n",
      "2025-09-20 23:12:21,204 - INFO - Use pytorch device_name: mps\n",
      "2025-09-20 23:12:21,205 - INFO - Load pretrained SentenceTransformer: Qwen/Qwen3-Embedding-0.6B\n",
      "2025-09-20 23:12:25,311 - INFO - 1 prompt is loaded, with the key: query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:25.312 INFO model_manager - _initialize_models: ✅ ModelManager: Shared AI models initialized successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:25,312 - INFO - ✅ ModelManager: Shared AI models initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:25.312 INFO evaluation - __init__: RAGEvaluator initialized with metrics: ['answer_relevancy', 'faithfulness', 'context_precision', 'context_recall']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:25,312 - INFO - RAGEvaluator initialized with metrics: ['answer_relevancy', 'faithfulness', 'context_precision', 'context_recall']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:25.313 INFO chunking_evaluation - __init__: Loaded 2 test queries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:25,313 - INFO - Loaded 2 test queries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive chunking evaluation...\n",
      "This may take a few minutes...\n",
      "\n",
      "2025-09-20 23:12:25.313 INFO chunking_evaluation - evaluate_all_strategies: Starting evaluation of all chunking strategies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:25,313 - INFO - Starting evaluation of all chunking strategies...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:25.313 INFO chunking_evaluation - evaluate_strategy: Evaluating baseline strategy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:25,313 - INFO - Evaluating baseline strategy...\n",
      "2025-09-20 23:12:25,715 - INFO - HTTP Request: GET https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:25.720 INFO baseline_rag - __init__: BaselineRAG pipeline initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:25,720 - INFO - BaselineRAG pipeline initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answers for queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:26,059 - INFO - HTTP Request: GET https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333/collections/baseline \"HTTP/1.1 200 OK\"\n",
      "2025-09-20 23:12:26,746 - INFO - HTTP Request: POST https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333/collections/baseline/points/query \"HTTP/1.1 200 OK\"\n",
      "2025-09-20 23:12:28,467 - INFO - HTTP Request: GET https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333/collections/baseline \"HTTP/1.1 200 OK\"\n",
      "2025-09-20 23:12:28,767 - INFO - HTTP Request: POST https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333/collections/baseline/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:30.290 INFO evaluation - evaluate_batch: 🔄 Evaluating 2 QA pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:30,290 - INFO - 🔄 Evaluating 2 QA pairs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:30.309 INFO evaluation - evaluate_batch: 🧮 Computing RAGAS metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:30,309 - INFO - 🧮 Computing RAGAS metrics...\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:21<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:53.929 INFO evaluation - evaluate_batch: ✅ Evaluation completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:53,929 - INFO - ✅ Evaluation completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:53.932 INFO chunking_evaluation - evaluate_strategy: ✅ baseline evaluation completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:53,932 - INFO - ✅ baseline evaluation completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:53.939 INFO chunking_evaluation - evaluate_strategy: Evaluating recursive_character strategy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:53,939 - INFO - Evaluating recursive_character strategy...\n",
      "2025-09-20 23:12:54,313 - INFO - HTTP Request: GET https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:54.317 INFO baseline_rag - __init__: BaselineRAG pipeline initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:54,317 - INFO - BaselineRAG pipeline initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answers for queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:54,640 - INFO - HTTP Request: GET https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333/collections/recursive_character \"HTTP/1.1 200 OK\"\n",
      "2025-09-20 23:12:54,985 - INFO - HTTP Request: POST https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333/collections/recursive_character/points/query \"HTTP/1.1 200 OK\"\n",
      "2025-09-20 23:12:56,709 - INFO - HTTP Request: GET https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333/collections/recursive_character \"HTTP/1.1 200 OK\"\n",
      "2025-09-20 23:12:56,955 - INFO - HTTP Request: POST https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333/collections/recursive_character/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:58.657 INFO evaluation - evaluate_batch: 🔄 Evaluating 2 QA pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:58,657 - INFO - 🔄 Evaluating 2 QA pairs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:58.667 INFO evaluation - evaluate_batch: 🧮 Computing RAGAS metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:12:58,667 - INFO - 🧮 Computing RAGAS metrics...\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:19<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:19.602 INFO evaluation - evaluate_batch: ✅ Evaluation completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:19,602 - INFO - ✅ Evaluation completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:19.605 INFO chunking_evaluation - evaluate_strategy: ✅ recursive_character evaluation completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:19,605 - INFO - ✅ recursive_character evaluation completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:19.611 INFO chunking_evaluation - evaluate_strategy: Evaluating unstructured strategy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:19,611 - INFO - Evaluating unstructured strategy...\n",
      "2025-09-20 23:13:19,989 - INFO - HTTP Request: GET https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:19.994 INFO baseline_rag - __init__: BaselineRAG pipeline initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:19,994 - INFO - BaselineRAG pipeline initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answers for queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:20,371 - INFO - HTTP Request: GET https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333/collections/unstructured \"HTTP/1.1 200 OK\"\n",
      "2025-09-20 23:13:20,705 - INFO - HTTP Request: POST https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333/collections/unstructured/points/query \"HTTP/1.1 200 OK\"\n",
      "2025-09-20 23:13:22,604 - INFO - HTTP Request: GET https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333/collections/unstructured \"HTTP/1.1 200 OK\"\n",
      "2025-09-20 23:13:22,904 - INFO - HTTP Request: POST https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333/collections/unstructured/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:23.644 INFO evaluation - evaluate_batch: 🔄 Evaluating 2 QA pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:23,644 - INFO - 🔄 Evaluating 2 QA pairs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:23.650 INFO evaluation - evaluate_batch: 🧮 Computing RAGAS metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:23,650 - INFO - 🧮 Computing RAGAS metrics...\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:18<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:42.806 INFO evaluation - evaluate_batch: ✅ Evaluation completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:42,806 - INFO - ✅ Evaluation completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:42.808 INFO chunking_evaluation - evaluate_strategy: ✅ unstructured evaluation completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:42,808 - INFO - ✅ unstructured evaluation completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:42.814 INFO chunking_evaluation - evaluate_strategy: Evaluating docling strategy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:42,814 - INFO - Evaluating docling strategy...\n",
      "2025-09-20 23:13:43,254 - INFO - HTTP Request: GET https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:43.258 INFO baseline_rag - __init__: BaselineRAG pipeline initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:43,258 - INFO - BaselineRAG pipeline initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answers for queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:43,606 - INFO - HTTP Request: GET https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333/collections/docling \"HTTP/1.1 200 OK\"\n",
      "2025-09-20 23:13:43,928 - INFO - HTTP Request: POST https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333/collections/docling/points/query \"HTTP/1.1 200 OK\"\n",
      "2025-09-20 23:13:45,552 - INFO - HTTP Request: GET https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333/collections/docling \"HTTP/1.1 200 OK\"\n",
      "2025-09-20 23:13:45,859 - INFO - HTTP Request: POST https://1d20b7dd-e936-4d2e-b034-c62a8dc85ef5.us-east4-0.gcp.cloud.qdrant.io:6333/collections/docling/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:46.268 INFO evaluation - evaluate_batch: 🔄 Evaluating 2 QA pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:46,268 - INFO - 🔄 Evaluating 2 QA pairs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:46.272 INFO evaluation - evaluate_batch: 🧮 Computing RAGAS metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:13:46,272 - INFO - 🧮 Computing RAGAS metrics...\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:14<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:14:03.503 INFO evaluation - evaluate_batch: ✅ Evaluation completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:14:03,503 - INFO - ✅ Evaluation completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:14:03.505 INFO chunking_evaluation - evaluate_strategy: ✅ docling evaluation completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:14:03,505 - INFO - ✅ docling evaluation completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:14:03.516 INFO chunking_evaluation - evaluate_all_strategies: ✅ All strategies evaluated successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 23:14:03,516 - INFO - ✅ All strategies evaluated successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation completed successfully!\n",
      "Results shape: (8, 7)\n"
     ]
    }
   ],
   "source": [
    "# Initialize comprehensive chunking evaluation framework\n",
    "# This evaluator will test all four chunking strategies against standardized queries\n",
    "evaluator = ChunkingEvaluator(\n",
    "    query_count=2,  # Number of test queries per strategy\n",
    "    metrics=[       # RAGAS evaluation metrics for comprehensive assessment\n",
    "        'answer_relevancy',    \n",
    "        'faithfulness',        \n",
    "        'context_precision',   \n",
    "        'context_recall'       \n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Starting comprehensive chunking evaluation...\")\n",
    "print(\"This process evaluates all strategies against standardized queries using RAGAS metrics.\")\n",
    "print(\"Expected duration: 3-5 minutes depending on system performance.\\n\")\n",
    "\n",
    "try:\n",
    "    # Execute evaluation across all chunking strategies\n",
    "    # This runs complete RAG pipelines for each strategy with identical test conditions\n",
    "    results_df = evaluator.evaluate_all_strategies()\n",
    "    print(\"\\nEvaluation completed successfully!\")\n",
    "    \n",
    "    # Provide summary of evaluation results\n",
    "    print(f\"Results matrix: {results_df.shape}\")\n",
    "    print(\"Analysis includes performance across all metrics and strategies\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Evaluation failed with error: {e}\")\n",
    "    print(\"Check vector database connectivity and API credentials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "📊 CHUNKING STRATEGY EVALUATION RESULTS\n",
      "================================================================================\n",
      "\n",
      "STRATEGY RANKINGS (by average score):\n",
      "--------------------------------------------------\n",
      "1. UNSTRUCTURED         | Avg: 0.976\n",
      "2. BASELINE             | Avg: 0.759\n",
      "3. RECURSIVE_CHARACTER  | Avg: 0.756\n",
      "4. DOCLING              | Avg: 0.600\n",
      "\n",
      "DETAILED METRICS:\n",
      "--------------------------------------------------------------------------------\n",
      "Strategy             Relevancy  Faithful   Precision  Recall     Average   \n",
      "--------------------------------------------------------------------------------\n",
      "unstructured         0.929      1.000      0.975      1.000      0.976     \n",
      "baseline             0.947      1.000      0.465      0.625      0.759     \n",
      "recursive_character  0.958      0.976      0.465      0.625      0.756     \n",
      "docling              0.497      1.000      0.402      0.500      0.600     \n",
      "\n",
      "KEY INSIGHTS:\n",
      "------------------------------\n",
      "• Best Strategy: UNSTRUCTURED (0.976)\n",
      "• Worst Strategy: DOCLING (0.600)\n",
      "• Performance Gap: 0.376 (62.7% improvement)\n",
      "\n",
      "BEST BY METRIC:\n",
      "-------------------------\n",
      "• Faithfulness      : UNSTRUCTURED (1.000)\n",
      "• Context Precision : UNSTRUCTURED (0.975)\n",
      "• Context Recall    : UNSTRUCTURED (1.000)\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display formatted results\n",
    "evaluator.print_results(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rag)",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
